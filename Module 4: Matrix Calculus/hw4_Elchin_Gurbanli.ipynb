{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Use the analytical solution to OLS on the data from HW1, to estimate the weight ofeach exam on the final grade:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Exam 1</th>\n",
       "      <th>Exam 2</th>\n",
       "      <th>Exam 3</th>\n",
       "      <th>Final Grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Student 1</th>\n",
       "      <td>89</td>\n",
       "      <td>93</td>\n",
       "      <td>83</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Student 2</th>\n",
       "      <td>100</td>\n",
       "      <td>86</td>\n",
       "      <td>78</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Student 3</th>\n",
       "      <td>97</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Student 4</th>\n",
       "      <td>83</td>\n",
       "      <td>99</td>\n",
       "      <td>100</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Student 5</th>\n",
       "      <td>100</td>\n",
       "      <td>81</td>\n",
       "      <td>75</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Exam 1  Exam 2  Exam 3  Final Grade\n",
       "Student 1      89      93      83           88\n",
       "Student 2     100      86      78           86\n",
       "Student 3      97      90      88           91\n",
       "Student 4      83      99     100           96\n",
       "Student 5     100      81      75           83"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.array([[89,93,83,88],\n",
    "                 [100,86,78,86],\n",
    "                 [97,90,88,91],\n",
    "                 [83,99,100,96],\n",
    "                 [100,81,75,83]])\n",
    "df = pd.DataFrame(data, columns = ['Exam 1','Exam 2','Exam 3','Final Grade'], \n",
    "                      index = ['Student {}'.format(i) for i in range(1,6)])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,:-1].values\n",
    "y = df.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\hat{\\beta} = (X^{T}X)^{-1}X^{T}y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.23083893, 0.33911109, 0.43272626])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([87.99827582, 86.00009513, 90.99128528, 96.00425515, 83.0063609 ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X @ b #should be equal to y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X @ b).round() == y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Exam 1</th>\n",
       "      <th>Exam 2</th>\n",
       "      <th>Exam 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Weights</th>\n",
       "      <td>0.230839</td>\n",
       "      <td>0.339111</td>\n",
       "      <td>0.432726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Exam 1    Exam 2    Exam 3\n",
       "Weights  0.230839  0.339111  0.432726"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = np.array([b[0], b[1], b[2]]).reshape(1,3)\n",
    "df_weights = pd.DataFrame(weights, columns = ['Exam 1', 'Exam 2', 'Exam 3'], index = ['Weights'])\n",
    "df_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that formula is, $$Final Grade = \\hat{\\beta}_1Exam1 + \\hat{\\beta}_2Exam2 + \\hat{\\beta}_3Exam3$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True Final grade</th>\n",
       "      <th>Predicted Final grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Student 1</th>\n",
       "      <td>88.0</td>\n",
       "      <td>87.998276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Student 2</th>\n",
       "      <td>86.0</td>\n",
       "      <td>86.000095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Student 3</th>\n",
       "      <td>91.0</td>\n",
       "      <td>90.991285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Student 4</th>\n",
       "      <td>96.0</td>\n",
       "      <td>96.004255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Student 5</th>\n",
       "      <td>83.0</td>\n",
       "      <td>83.006361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           True Final grade  Predicted Final grade\n",
       "Student 1              88.0              87.998276\n",
       "Student 2              86.0              86.000095\n",
       "Student 3              91.0              90.991285\n",
       "Student 4              96.0              96.004255\n",
       "Student 5              83.0              83.006361"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_FinalGrades = np.array([df.iloc[i,0] * b[0] + df.iloc[i,1] * b[1] + df.iloc[i,2] * b[2] for i in range(0,5)])\n",
    "\n",
    "concat_true_predicted = np.concatenate((y.reshape(5,1), predicted_FinalGrades.reshape(5,1)), axis = 1)\n",
    "df_true_predicted = pd.DataFrame(concat_true_predicted, columns = ['True Final grade', 'Predicted Final grade'],\n",
    "                            index = ['Student {}'.format(i) for i in range(1,6)])\n",
    "df_true_predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last retouchings, i.e, rounding the values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True Final grade</th>\n",
       "      <th>Predicted Final grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Student 1</th>\n",
       "      <td>88.0</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Student 2</th>\n",
       "      <td>86.0</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Student 3</th>\n",
       "      <td>91.0</td>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Student 4</th>\n",
       "      <td>96.0</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Student 5</th>\n",
       "      <td>83.0</td>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           True Final grade  Predicted Final grade\n",
       "Student 1              88.0                   88.0\n",
       "Student 2              86.0                   86.0\n",
       "Student 3              91.0                   91.0\n",
       "Student 4              96.0                   96.0\n",
       "Student 5              83.0                   83.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_true_predicted['Predicted Final grade'] = df_true_predicted['Predicted Final grade'].round()\n",
    "df_true_predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Use the same data, but now find the weights using gradient descent. Guidance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 160000/160000 [00:02<00:00, 67925.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The last 5 values of error [0.0001375 0.0001375 0.0001375 0.0001375 0.0001375 0.0001375 0.0001375\n",
      " 0.0001375 0.0001375 0.0001375]\n",
      "\n",
      "The weights that were found with gradient descend are [0.23083893 0.33911109 0.43272626]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 160000 #a---> number of epochs\n",
    "step_size = 8e-6 # d---> the least value I could come up with while playing with numbers\n",
    "error_history = [] #empty list to collect the values of errors\n",
    "\n",
    "def OLS_gradient_descent(X, y, step_size, termination_crieria):\n",
    "    a = np.random.random(3) #three initial random values for a as test values for exam weights\n",
    "    for i in tqdm(range(termination_crieria)):\n",
    "        error = np.sum(np.square(a.T @ X.T - y.T)) #b--->calculating the error\n",
    "        error_history.append(np.log(error)) #adding current error to array\n",
    "        current_gradient = 2 * (a.T @ X.T - y.T) @ X #calculating current gradient\n",
    "        a = a - step_size * current_gradient #calculating the weights with using current-gradient and step size\n",
    "    print(\"The last 5 values of error {}\\n\".format(np.exp(error_history[-10:])))\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.ylabel(\"log-error\")\n",
    "    plt.plot(np.arange(epochs), error_history) #c---> ploting the error\n",
    "    print(\"The weights that were found with gradient descend are {}\".format(a))\n",
    "\n",
    "OLS_gradient_descent(X, y, step_size, termination_crieria=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may observe that the errors(the last 10 error values in the array) are no greater than 0.001375. It means that our gradient descent algorithm is correct and the errors are negligibly small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Examine what happens to the gradient descent algorithm with different step sizes.Write a short summary of your conclusions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best step size I could find is $10^{-6} <= step size <= 8*10^{-6}$  . I tested several values, in higher from this values the gradients will be exploded, and it will give us nan values, and lower than this values will take a lot of time to convergence. That is why in my opinion, step sized from given interval is best to use in this gradient descend algorithm"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit (conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
